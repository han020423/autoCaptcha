{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837a334d-e628-4392-8eb1-fc648c7e8b22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2827/2827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 190ms/step - dense_1_accuracy: 0.0157 - dense_1_loss: 4.1108 - dense_2_accuracy: 0.0170 - dense_2_loss: 4.1101 - dense_3_accuracy: 0.0168 - dense_3_loss: 4.1113 - dense_4_accuracy: 0.0171 - dense_4_loss: 4.1109 - dense_accuracy: 0.0217 - dense_loss: 3.9252 - loss: 20.3683 - val_dense_1_accuracy: 0.0175 - val_dense_1_loss: 4.0985 - val_dense_2_accuracy: 0.0169 - val_dense_2_loss: 4.0986 - val_dense_3_accuracy: 0.0157 - val_dense_3_loss: 4.1025 - val_dense_4_accuracy: 0.0168 - val_dense_4_loss: 4.0963 - val_dense_accuracy: 0.0000e+00 - val_dense_loss: 8.3722 - val_loss: 24.7680\n",
      "Epoch 2/20\n",
      "\u001b[1m2827/2827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 186ms/step - dense_1_accuracy: 0.0265 - dense_1_loss: 4.0583 - dense_2_accuracy: 0.0238 - dense_2_loss: 4.0676 - dense_3_accuracy: 0.0244 - dense_3_loss: 4.0682 - dense_4_accuracy: 0.0256 - dense_4_loss: 4.0546 - dense_accuracy: 0.0331 - dense_loss: 3.8235 - loss: 20.0722 - val_dense_1_accuracy: 0.0955 - val_dense_1_loss: 3.6529 - val_dense_2_accuracy: 0.0893 - val_dense_2_loss: 3.6860 - val_dense_3_accuracy: 0.0855 - val_dense_3_loss: 3.7342 - val_dense_4_accuracy: 0.1213 - val_dense_4_loss: 3.5079 - val_dense_accuracy: 2.6533e-04 - val_dense_loss: 15.7544 - val_loss: 30.3358\n",
      "Epoch 3/20\n",
      "\u001b[1m2827/2827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 188ms/step - dense_1_accuracy: 0.1252 - dense_1_loss: 3.4794 - dense_2_accuracy: 0.1093 - dense_2_loss: 3.5724 - dense_3_accuracy: 0.1082 - dense_3_loss: 3.5931 - dense_4_accuracy: 0.1459 - dense_4_loss: 3.3262 - dense_accuracy: 0.1933 - dense_loss: 2.9848 - loss: 16.9559 - val_dense_1_accuracy: 0.1495 - val_dense_1_loss: 3.3985 - val_dense_2_accuracy: 0.1460 - val_dense_2_loss: 3.3768 - val_dense_3_accuracy: 0.1368 - val_dense_3_loss: 3.4392 - val_dense_4_accuracy: 0.1999 - val_dense_4_loss: 3.0845 - val_dense_accuracy: 2.6533e-04 - val_dense_loss: 16.0011 - val_loss: 29.3011\n",
      "Epoch 4/20\n",
      "\u001b[1m1121/2827\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4:46\u001b[0m 168ms/step - dense_1_accuracy: 0.1766 - dense_1_loss: 3.1908 - dense_2_accuracy: 0.1607 - dense_2_loss: 3.3235 - dense_3_accuracy: 0.1554 - dense_3_loss: 3.3286 - dense_4_accuracy: 0.2203 - dense_4_loss: 2.9619 - dense_accuracy: 0.2692 - dense_loss: 2.6066 - loss: 15.4113"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 115\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m    114\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model()\n\u001b[1;32m--> 115\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X, y_split, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1684\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1685\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1686\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1687\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1688\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1689\u001b[0m   )\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# 데이터셋 로딩 및 전처리\n",
    "def load_data(captcha_folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(captcha_folder):\n",
    "        if filename.endswith('.jpg'):  # 이미지 파일만 처리\n",
    "            image_path = os.path.join(captcha_folder, filename)\n",
    "            # 이미지 읽기\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (150, 40))  # 크기 조정\n",
    "            image = image / 255.0  # 정규화\n",
    "            \n",
    "            # 레이블 추출 (파일명에서 확장자를 제거하고, 문자를 레이블로 사용)\n",
    "            label = filename.split('.')[0]  # 파일명에서 확장자 제거\n",
    "            labels.append(label)\n",
    "            images.append(image)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    images = images.reshape(-1, 40, 150, 1)  # CNN 입력 형태에 맞게 차원 변경\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def encode_label(label):\n",
    "    encoded_label = []\n",
    "    for c in label:\n",
    "        if c.isdigit():\n",
    "            encoded_label.append(ord(c) - ord('0'))  # 숫자\n",
    "        elif c.islower():\n",
    "            encoded_label.append(ord(c) - ord('a') + 10)  # 소문자\n",
    "        else:\n",
    "            encoded_label.append(ord(c) - ord('A') + 36)  # 대문자\n",
    "    return encoded_label\n",
    "\n",
    "def preprocess_labels(y):\n",
    "    y_encoded = []\n",
    "    for label in y:\n",
    "        encoded_label = encode_label(label)\n",
    "        while len(encoded_label) < 5:\n",
    "            encoded_label.append(62)  # 공백을 나타내는 62번 인덱스를 사용\n",
    "        y_encoded.append(encoded_label)\n",
    "\n",
    "    y_encoded = np.array(y_encoded)\n",
    "\n",
    "    # 레이블을 one-hot 인코딩\n",
    "    y_encoded_onehot = []\n",
    "    for label in y_encoded:\n",
    "        onehot_label = [to_categorical(l, num_classes=62) for l in label]  # 62개의 클래스에 대해 one-hot 인코딩\n",
    "        y_encoded_onehot.append(onehot_label)\n",
    "\n",
    "    y_encoded_onehot = np.array(y_encoded_onehot)\n",
    "    \n",
    "    # 레이블을 5개의 출력에 맞게 분리\n",
    "    y_split = [y_encoded_onehot[:, i] for i in range(5)]  # 각 문자에 대해 one-hot 인코딩\n",
    "    return y_split\n",
    "\n",
    "def build_model():\n",
    "    input_layer = Input(shape=(40, 150, 1))\n",
    "\n",
    "    # 첫 번째 Convolutional 블록\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # 두 번째 Convolutional 블록\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # 세 번째 Convolutional 블록\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Flatten 층과 드롭아웃\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # 출력층 (5개의 문자에 대해 각각 62개의 클래스를 예측)\n",
    "    outputs = [Dense(62, activation='softmax')(x) for _ in range(5)]\n",
    "    \n",
    "    # 모델 정의\n",
    "    model = Model(inputs=input_layer, outputs=outputs)\n",
    "    \n",
    "    # 학습률 조정\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    \n",
    "    # 손실 함수 (다중 출력 손실 합산)\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        total_loss = 0\n",
    "        for i in range(5):\n",
    "            total_loss += K.categorical_crossentropy(y_true[i], y_pred[i])\n",
    "        return total_loss / 5\n",
    "    \n",
    "    # 모델 컴파일 (각 출력에 대해 정확도 계산)\n",
    "    model.compile(optimizer=optimizer, loss=custom_loss, metrics=['accuracy'] * 5)  # 각 출력에 대해 accuracy를 설정\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 데이터 로딩\n",
    "captcha_folder = './CAPTCHA'\n",
    "X, y = load_data(captcha_folder)\n",
    "\n",
    "# 레이블 전처리\n",
    "y_split = preprocess_labels(y)\n",
    "\n",
    "# 모델 학습\n",
    "model = build_model()\n",
    "model.fit(X, y_split, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba57f0e1-22a2-4615-8ccd-d1217bd704b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 546ms/step - char_1_accuracy: 0.6554 - char_1_loss: 2.4175 - char_2_accuracy: 0.0360 - char_2_loss: 4.0379 - char_3_accuracy: 0.0073 - char_3_loss: 4.2480 - char_4_accuracy: 0.0118 - char_4_loss: 4.2570 - char_5_accuracy: 0.0184 - char_5_loss: 4.2722 - loss: 19.2556 - val_char_1_accuracy: 0.4478 - val_char_1_loss: 4.0605 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 4.1503 - val_char_3_accuracy: 0.0000e+00 - val_char_3_loss: 4.1380 - val_char_4_accuracy: 0.0000e+00 - val_char_4_loss: 4.1289 - val_char_5_accuracy: 0.0299 - val_char_5_loss: 4.1181 - val_loss: 20.5838\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 350ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0859 - char_2_accuracy: 0.1554 - char_2_loss: 2.8469 - char_3_accuracy: 0.0182 - char_3_loss: 4.0954 - char_4_accuracy: 0.0446 - char_4_loss: 4.1248 - char_5_accuracy: 0.0317 - char_5_loss: 4.0728 - loss: 15.2278 - val_char_1_accuracy: 0.5522 - val_char_1_loss: 3.7300 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 4.2516 - val_char_3_accuracy: 0.0000e+00 - val_char_3_loss: 4.1642 - val_char_4_accuracy: 0.0448 - val_char_4_loss: 4.0899 - val_char_5_accuracy: 0.0149 - val_char_5_loss: 4.0868 - val_loss: 20.2995\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 364ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0202 - char_2_accuracy: 0.2142 - char_2_loss: 2.3715 - char_3_accuracy: 0.0610 - char_3_loss: 3.8743 - char_4_accuracy: 0.0436 - char_4_loss: 3.9640 - char_5_accuracy: 0.0393 - char_5_loss: 3.9021 - loss: 14.1343 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 2.2578 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 4.5411 - val_char_3_accuracy: 0.0000e+00 - val_char_3_loss: 4.1843 - val_char_4_accuracy: 0.0149 - val_char_4_loss: 4.0660 - val_char_5_accuracy: 0.0149 - val_char_5_loss: 4.0702 - val_loss: 19.0817\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 338ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0144 - char_2_accuracy: 0.1873 - char_2_loss: 2.2712 - char_3_accuracy: 0.0681 - char_3_loss: 3.8129 - char_4_accuracy: 0.0706 - char_4_loss: 3.8447 - char_5_accuracy: 0.0731 - char_5_loss: 3.8181 - loss: 13.7629 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 1.6816 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 4.8168 - val_char_3_accuracy: 0.0000e+00 - val_char_3_loss: 4.2031 - val_char_4_accuracy: 0.0299 - val_char_4_loss: 4.0853 - val_char_5_accuracy: 0.0149 - val_char_5_loss: 4.0471 - val_loss: 18.8406\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 348ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0141 - char_2_accuracy: 0.2023 - char_2_loss: 2.1938 - char_3_accuracy: 0.0686 - char_3_loss: 3.7483 - char_4_accuracy: 0.0625 - char_4_loss: 3.7851 - char_5_accuracy: 0.0859 - char_5_loss: 3.7719 - loss: 13.5077 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.4800 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 5.2263 - val_char_3_accuracy: 0.0299 - val_char_3_loss: 4.2346 - val_char_4_accuracy: 0.0299 - val_char_4_loss: 4.2041 - val_char_5_accuracy: 0.0448 - val_char_5_loss: 4.0776 - val_loss: 18.1122\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 359ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0110 - char_2_accuracy: 0.2828 - char_2_loss: 2.0491 - char_3_accuracy: 0.0934 - char_3_loss: 3.6422 - char_4_accuracy: 0.0874 - char_4_loss: 3.6617 - char_5_accuracy: 0.0583 - char_5_loss: 3.6864 - loss: 13.0443 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.1685 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 5.6122 - val_char_3_accuracy: 0.0000e+00 - val_char_3_loss: 4.2581 - val_char_4_accuracy: 0.0299 - val_char_4_loss: 4.2925 - val_char_5_accuracy: 0.0000e+00 - val_char_5_loss: 4.1513 - val_loss: 18.2784\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 332ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0103 - char_2_accuracy: 0.3099 - char_2_loss: 2.0601 - char_3_accuracy: 0.1371 - char_3_loss: 3.5128 - char_4_accuracy: 0.1254 - char_4_loss: 3.5200 - char_5_accuracy: 0.1591 - char_5_loss: 3.5934 - loss: 12.6981 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.1180 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 5.6899 - val_char_3_accuracy: 0.0000e+00 - val_char_3_loss: 4.3242 - val_char_4_accuracy: 0.0448 - val_char_4_loss: 4.2601 - val_char_5_accuracy: 0.0448 - val_char_5_loss: 4.2822 - val_loss: 18.4222\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 343ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0106 - char_2_accuracy: 0.3826 - char_2_loss: 1.8366 - char_3_accuracy: 0.1374 - char_3_loss: 3.4428 - char_4_accuracy: 0.1600 - char_4_loss: 3.4871 - char_5_accuracy: 0.1625 - char_5_loss: 3.4203 - loss: 12.1918 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.0571 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 6.0757 - val_char_3_accuracy: 0.0149 - val_char_3_loss: 4.3769 - val_char_4_accuracy: 0.0299 - val_char_4_loss: 4.3784 - val_char_5_accuracy: 0.0448 - val_char_5_loss: 4.4201 - val_loss: 18.9453\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 354ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0126 - char_2_accuracy: 0.3619 - char_2_loss: 1.9395 - char_3_accuracy: 0.2432 - char_3_loss: 3.2948 - char_4_accuracy: 0.1672 - char_4_loss: 3.3283 - char_5_accuracy: 0.2338 - char_5_loss: 3.2862 - loss: 11.8396 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.0465 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 6.2042 - val_char_3_accuracy: 0.0149 - val_char_3_loss: 4.3708 - val_char_4_accuracy: 0.0299 - val_char_4_loss: 4.4991 - val_char_5_accuracy: 0.0448 - val_char_5_loss: 4.4466 - val_loss: 19.1556\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 357ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0144 - char_2_accuracy: 0.4050 - char_2_loss: 1.8329 - char_3_accuracy: 0.2538 - char_3_loss: 3.1969 - char_4_accuracy: 0.2318 - char_4_loss: 3.1748 - char_5_accuracy: 0.2266 - char_5_loss: 3.2212 - loss: 11.4332 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.0226 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 6.5040 - val_char_3_accuracy: 0.0299 - val_char_3_loss: 4.4508 - val_char_4_accuracy: 0.0000e+00 - val_char_4_loss: 4.7455 - val_char_5_accuracy: 0.0448 - val_char_5_loss: 4.3568 - val_loss: 19.6154\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 349ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0123 - char_2_accuracy: 0.4395 - char_2_loss: 1.7100 - char_3_accuracy: 0.2084 - char_3_loss: 3.1169 - char_4_accuracy: 0.2709 - char_4_loss: 3.0708 - char_5_accuracy: 0.3168 - char_5_loss: 3.1104 - loss: 11.0025 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.0560 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 6.1001 - val_char_3_accuracy: 0.0000e+00 - val_char_3_loss: 4.3988 - val_char_4_accuracy: 0.0000e+00 - val_char_4_loss: 4.7012 - val_char_5_accuracy: 0.0448 - val_char_5_loss: 4.5269 - val_loss: 19.4703\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 348ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0114 - char_2_accuracy: 0.3990 - char_2_loss: 1.7060 - char_3_accuracy: 0.2878 - char_3_loss: 2.9862 - char_4_accuracy: 0.2887 - char_4_loss: 2.9765 - char_5_accuracy: 0.2298 - char_5_loss: 3.0870 - loss: 10.7588 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.0250 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 6.4349 - val_char_3_accuracy: 0.0299 - val_char_3_loss: 4.4832 - val_char_4_accuracy: 0.0000e+00 - val_char_4_loss: 4.7878 - val_char_5_accuracy: 0.0448 - val_char_5_loss: 4.5933 - val_loss: 19.8042\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 354ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0132 - char_2_accuracy: 0.5278 - char_2_loss: 1.5691 - char_3_accuracy: 0.3185 - char_3_loss: 2.8823 - char_4_accuracy: 0.3162 - char_4_loss: 2.8534 - char_5_accuracy: 0.2809 - char_5_loss: 2.8902 - loss: 10.1977 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.0291 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 6.4054 - val_char_3_accuracy: 0.0299 - val_char_3_loss: 4.5300 - val_char_4_accuracy: 0.0000e+00 - val_char_4_loss: 4.8436 - val_char_5_accuracy: 0.0448 - val_char_5_loss: 4.6715 - val_loss: 19.9973\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 325ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0123 - char_2_accuracy: 0.4924 - char_2_loss: 1.5492 - char_3_accuracy: 0.2992 - char_3_loss: 2.8585 - char_4_accuracy: 0.3618 - char_4_loss: 2.7821 - char_5_accuracy: 0.3919 - char_5_loss: 2.7399 - loss: 9.9497 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.0113 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 6.7619 - val_char_3_accuracy: 0.0000e+00 - val_char_3_loss: 4.5851 - val_char_4_accuracy: 0.0000e+00 - val_char_4_loss: 4.9705 - val_char_5_accuracy: 0.0448 - val_char_5_loss: 4.7617 - val_loss: 20.6025\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 338ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0129 - char_2_accuracy: 0.6133 - char_2_loss: 1.4141 - char_3_accuracy: 0.4714 - char_3_loss: 2.5207 - char_4_accuracy: 0.4341 - char_4_loss: 2.5591 - char_5_accuracy: 0.4041 - char_5_loss: 2.6103 - loss: 9.1106 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.0134 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 6.4026 - val_char_3_accuracy: 0.0299 - val_char_3_loss: 4.5071 - val_char_4_accuracy: 0.0000e+00 - val_char_4_loss: 5.1357 - val_char_5_accuracy: 0.0448 - val_char_5_loss: 4.7434 - val_loss: 20.2722\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 314ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0091 - char_2_accuracy: 0.6646 - char_2_loss: 1.3021 - char_3_accuracy: 0.4564 - char_3_loss: 2.5090 - char_4_accuracy: 0.4707 - char_4_loss: 2.4265 - char_5_accuracy: 0.4775 - char_5_loss: 2.4231 - loss: 8.6633 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.0058 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 6.9187 - val_char_3_accuracy: 0.0000e+00 - val_char_3_loss: 4.6100 - val_char_4_accuracy: 0.0000e+00 - val_char_4_loss: 5.2567 - val_char_5_accuracy: 0.0448 - val_char_5_loss: 4.8574 - val_loss: 21.1054\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 331ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0080 - char_2_accuracy: 0.6574 - char_2_loss: 1.2736 - char_3_accuracy: 0.5250 - char_3_loss: 2.2732 - char_4_accuracy: 0.5219 - char_4_loss: 2.3327 - char_5_accuracy: 0.5081 - char_5_loss: 2.2793 - loss: 8.1530 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.0088 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 6.7894 - val_char_3_accuracy: 0.0149 - val_char_3_loss: 4.6938 - val_char_4_accuracy: 0.0000e+00 - val_char_4_loss: 5.2971 - val_char_5_accuracy: 0.0448 - val_char_5_loss: 4.7354 - val_loss: 21.1121\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 306ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0081 - char_2_accuracy: 0.6797 - char_2_loss: 1.1718 - char_3_accuracy: 0.5511 - char_3_loss: 2.1754 - char_4_accuracy: 0.5564 - char_4_loss: 2.1385 - char_5_accuracy: 0.5975 - char_5_loss: 2.0614 - loss: 7.5472 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.0663 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 5.8947 - val_char_3_accuracy: 0.0149 - val_char_3_loss: 4.6385 - val_char_4_accuracy: 0.0000e+00 - val_char_4_loss: 5.1370 - val_char_5_accuracy: 0.0448 - val_char_5_loss: 4.6330 - val_loss: 20.0566\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 315ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0099 - char_2_accuracy: 0.7988 - char_2_loss: 0.9953 - char_3_accuracy: 0.5699 - char_3_loss: 2.0713 - char_4_accuracy: 0.6540 - char_4_loss: 2.0316 - char_5_accuracy: 0.6023 - char_5_loss: 2.0104 - loss: 7.1217 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.0110 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 6.6499 - val_char_3_accuracy: 0.0000e+00 - val_char_3_loss: 4.9992 - val_char_4_accuracy: 0.0000e+00 - val_char_4_loss: 5.3690 - val_char_5_accuracy: 0.0448 - val_char_5_loss: 4.9971 - val_loss: 21.4590\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 319ms/step - char_1_accuracy: 1.0000 - char_1_loss: 0.0102 - char_2_accuracy: 0.7685 - char_2_loss: 1.0142 - char_3_accuracy: 0.6515 - char_3_loss: 1.8997 - char_4_accuracy: 0.7297 - char_4_loss: 1.8420 - char_5_accuracy: 0.6878 - char_5_loss: 1.8736 - loss: 6.6358 - val_char_1_accuracy: 1.0000 - val_char_1_loss: 0.1191 - val_char_2_accuracy: 0.0000e+00 - val_char_2_loss: 5.4755 - val_char_3_accuracy: 0.0000e+00 - val_char_3_loss: 4.6172 - val_char_4_accuracy: 0.0000e+00 - val_char_4_loss: 5.2145 - val_char_5_accuracy: 0.0448 - val_char_5_loss: 4.8747 - val_loss: 19.9813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22f65c8a210>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modelv2\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization, LSTM, TimeDistributed, Bidirectional, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# 데이터셋 로딩 및 전처리\n",
    "def load_data(captcha_folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(captcha_folder):\n",
    "        if filename.endswith('.jpg'):  # 이미지 파일만 처리\n",
    "            image_path = os.path.join(captcha_folder, filename)\n",
    "            # 이미지 읽기\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (150, 40))  # 크기 조정\n",
    "            image = image / 255.0  # 정규화\n",
    "            \n",
    "            # 레이블 추출 (파일명에서 확장자를 제거하고, 문자를 레이블로 사용)\n",
    "            label = filename.split('.')[0]  # 파일명에서 확장자 제거\n",
    "            labels.append(label)\n",
    "            images.append(image)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    images = images.reshape(-1, 40, 150, 1)  # CNN 입력 형태에 맞게 차원 변경\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def encode_label(label):\n",
    "    encoded_label = []\n",
    "    for c in label:\n",
    "        if c.isdigit():\n",
    "            encoded_label.append(ord(c) - ord('0'))  # 숫자\n",
    "        elif c.islower():\n",
    "            encoded_label.append(ord(c) - ord('a') + 10)  # 소문자\n",
    "        else:\n",
    "            encoded_label.append(ord(c) - ord('A') + 36)  # 대문자\n",
    "    return encoded_label\n",
    "\n",
    "def preprocess_labels(y):\n",
    "    y_encoded = []\n",
    "    for label in y:\n",
    "        encoded_label = encode_label(label)\n",
    "        while len(encoded_label) < 5:\n",
    "            encoded_label.append(62)  # 공백을 나타내는 62번 인덱스를 사용\n",
    "        y_encoded.append(encoded_label)\n",
    "\n",
    "    y_encoded = np.array(y_encoded)\n",
    "\n",
    "    # 레이블을 one-hot 인코딩\n",
    "    y_encoded_onehot = []\n",
    "    for label in y_encoded:\n",
    "        onehot_label = [to_categorical(l, num_classes=62) for l in label]  # 62개의 클래스에 대해 one-hot 인코딩\n",
    "        y_encoded_onehot.append(onehot_label)\n",
    "\n",
    "    y_encoded_onehot = np.array(y_encoded_onehot)\n",
    "    \n",
    "    # 레이블을 5개의 출력에 맞게 분리\n",
    "    y_split = [y_encoded_onehot[:, i] for i in range(5)]  # 각 문자에 대해 one-hot 인코딩\n",
    "    return y_split\n",
    "\n",
    "def build_model():\n",
    "    input_layer = Input(shape=(40, 150, 1))\n",
    "\n",
    "    # 첫 번째 Convolutional 블록\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # 두 번째 Convolutional 블록\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # 세 번째 Convolutional 블록\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # 네 번째 Convolutional 블록\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Reshape((-1, x.shape[-1]))(x) \n",
    "    # LSTM 레이어\n",
    "    x = Bidirectional(LSTM(128, return_sequences=False))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # 출력층 (5개의 문자에 대해 각각 62개의 클래스를 예측)\n",
    "    outputs = [Dense(62, activation='softmax', name=f'char_{i+1}')(x) for i in range(5)]\n",
    "    \n",
    "    # 모델 정의\n",
    "    model = Model(inputs=input_layer, outputs=outputs)\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy'] * 5\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 데이터 로딩\n",
    "captcha_folder = './cap'\n",
    "X, y = load_data(captcha_folder)\n",
    "\n",
    "# 레이블 전처리\n",
    "y_split = preprocess_labels(y)\n",
    "\n",
    "# 모델 학습\n",
    "model = build_model()\n",
    "model.fit(X, y_split, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "model.save('captcha_model_v2.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40e2c931-4fcd-43d5-b330-971bb15594f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_3               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ char_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,934</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ char_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,934</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ char_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,934</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ char_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,934</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ char_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,934</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m320\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m128\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m512\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │           \u001b[38;5;34m1,024\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling2d_3               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │         \u001b[38;5;34m394,240\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ char_1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m)                │          \u001b[38;5;34m15,934\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ char_2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m)                │          \u001b[38;5;34m15,934\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ char_3 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m)                │          \u001b[38;5;34m15,934\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ char_4 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m)                │          \u001b[38;5;34m15,934\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ char_5 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m)                │          \u001b[38;5;34m15,934\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,589,092</span> (9.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,589,092\u001b[0m (9.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">862,710</span> (3.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m862,710\u001b[0m (3.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,725,422</span> (6.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,725,422\u001b[0m (6.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7deb20d4-8242-450e-b32a-587fa80c8ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('captcha_model_v2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ebe6858-447e-4678-bf22-aada117a393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('captcha_model_v2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b9902ab6-2a60-4774-8add-e98cb1a8363a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "Predicted text for the image: 1KAHZ\n"
     ]
    }
   ],
   "source": [
    "# 숫자 라벨을 알파벳과 숫자로 변환하는 함수\n",
    "def label_to_char(label):\n",
    "    if label < 10:\n",
    "        return chr(label + ord('0'))  # 숫자 '0'~'9'\n",
    "    elif label < 36:\n",
    "        return chr(label - 10 + ord('a'))  # 소문자 'a'~'z'\n",
    "    else:\n",
    "        return chr(label - 36 + ord('A'))  # 대문자 'A'~'Z'\n",
    "\n",
    "# 이미지 예측 후 알파벳/숫자 변환\n",
    "def predict_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (150, 40))  # 이미지 크기 변경\n",
    "    image = image / 255.0  # 정규화\n",
    "    image = image.reshape(1, 40, 150, 1)  # 배치 차원 추가\n",
    "\n",
    "    # 예측하기\n",
    "    predictions = model.predict(image)\n",
    "    \n",
    "    predicted_labels = []\n",
    "    for i in range(5):\n",
    "        predicted_class = np.argmax(predictions[i][0])  # 첫 번째 문자 예측\n",
    "        predicted_labels.append(predicted_class)\n",
    "\n",
    "    # 숫자 라벨을 문자로 변환\n",
    "    predicted_chars = [label_to_char(label) for label in predicted_labels]\n",
    "    \n",
    "    return ''.join(predicted_chars)\n",
    "\n",
    "# 예시: 이미지 예측\n",
    "predicted_text = predict_image('./CAPTCHA/QSbwI.jpg')  # 예측할 이미지 경로\n",
    "print(f\"Predicted text for the image: {predicted_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b32830b-15e4-48bf-9d73-ad9795d9492e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002CD71C2DDA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002CD71C2DDA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896ms/step\n",
      "Predicted text for the image: swrEk\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 숫자 라벨을 알파벳과 숫자로 변환하는 함수\n",
    "def label_to_char(label):\n",
    "    if label < 10:\n",
    "        return chr(label + ord('0'))  # 숫자 '0'~'9'\n",
    "    elif label < 36:\n",
    "        return chr(label - 10 + ord('a'))  # 소문자 'a'~'z'\n",
    "    else:\n",
    "        return chr(label - 36 + ord('A'))  # 대문자 'A'~'Z'\n",
    "\n",
    "# 이미지 예측 후 알파벳/숫자 변환\n",
    "def predict_image(image_path, model):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (150, 40))  # 이미지 크기 변경\n",
    "    image = image / 255.0  # 정규화\n",
    "    image = image.reshape(1, 40, 150, 1)  # 배치 차원 추가\n",
    "\n",
    "    # 예측하기\n",
    "    predictions = model.predict(image)\n",
    "    \n",
    "    predicted_labels = []\n",
    "    for i in range(5):\n",
    "        predicted_class = np.argmax(predictions[i][0])  # 첫 번째 문자 예측\n",
    "        predicted_labels.append(predicted_class)\n",
    "\n",
    "    # 숫자 라벨을 문자로 변환\n",
    "    predicted_chars = [label_to_char(label) for label in predicted_labels]\n",
    "    \n",
    "    return ''.join(predicted_chars)\n",
    "\n",
    "# 저장된 모델 로드\n",
    "model = load_model('captcha_model_v2.h5')\n",
    "\n",
    "# 예시: 이미지 예측\n",
    "predicted_text = predict_image('./22222.png', model)  # 예측할 이미지 경로\n",
    "print(f\"Predicted text for the image: {predicted_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0496822-8872-447d-9b7b-01db1781bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old code 70%\n",
    "\n",
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, GlobalAveragePooling2D\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# # 데이터셋 로딩 및 전처리\n",
    "# def load_data(captcha_folder):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "    \n",
    "#     for filename in os.listdir(captcha_folder):\n",
    "#         if filename.endswith('.jpg'):  # 이미지 파일만 처리\n",
    "#             image_path = os.path.join(captcha_folder, filename)\n",
    "#             # 이미지 읽기\n",
    "#             image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#             image = cv2.resize(image, (150, 40))  # 크기 조정\n",
    "#             image = image / 255.0  # 정규화\n",
    "            \n",
    "#             # 레이블 추출 (파일명에서 확장자를 제거하고, 문자를 레이블로 사용)\n",
    "#             label = filename.split('.')[0]  # 파일명에서 확장자 제거\n",
    "#             labels.append(label)\n",
    "#             images.append(image)\n",
    "    \n",
    "#     images = np.array(images)\n",
    "#     images = images.reshape(-1, 40, 150, 1)  # CNN 입력 형태에 맞게 차원 변경\n",
    "    \n",
    "#     return images, labels\n",
    "\n",
    "# # 모델 정의\n",
    "# def build_model():\n",
    "#     input_img = Input(shape=(40, 150, 1))\n",
    "\n",
    "#     x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "#     x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "#     x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "#     x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "\n",
    "#     # 각 문자를 별도로 예측하기 위한 5개의 출력층\n",
    "#     output = []\n",
    "#     for _ in range(5):\n",
    "#         output.append(Dense(62, activation='softmax')(x))\n",
    "\n",
    "#     model = Model(inputs=input_img, outputs=output)\n",
    "#     model.compile(optimizer=Adam(learning_rate=0.0001 ), \n",
    "#                   loss='categorical_crossentropy', \n",
    "#                   metrics=['accuracy'] * 5)\n",
    "\n",
    "#     return model\n",
    "# # 데이터 로딩\n",
    "# captcha_folder = './CAPTCHA'\n",
    "# X, y = load_data(captcha_folder)\n",
    "\n",
    "# # 레이블을 one-hot 인코딩\n",
    "# y_encoded = []\n",
    "# for label in y:\n",
    "#     encoded_label = []\n",
    "#     for c in label:\n",
    "#         if c.isdigit():\n",
    "#             encoded_label.append(ord(c) - ord('0'))  # 숫자\n",
    "#         elif c.islower():\n",
    "#             encoded_label.append(ord(c) - ord('a') + 10)  # 소문자\n",
    "#         else:\n",
    "#             encoded_label.append(ord(c) - ord('A') + 36)  # 대문자\n",
    "#     # 레이블을 길이가 5로 고정\n",
    "#     while len(encoded_label) < 5:\n",
    "#         encoded_label.append(62)  # 공백을 나타내는 62번 인덱스를 사용\n",
    "#     y_encoded.append(encoded_label)\n",
    "\n",
    "# y_encoded = np.array(y_encoded)\n",
    "# # 각 문자의 레이블을 one-hot 인코딩\n",
    "# y_split = [to_categorical(y_encoded[:, i], num_classes=62) for i in range(5)]\n",
    "\n",
    "# # 모델 학습\n",
    "# model = build_model()\n",
    "# model.fit(X, y_split, epochs=15, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# 현재 코드는 다음과 같아"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
